{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":5311975,"sourceType":"datasetVersion","datasetId":3087285}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import wandb\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2025-04-03T10:17:41.560221Z","iopub.execute_input":"2025-04-03T10:17:41.560560Z","iopub.status.idle":"2025-04-03T10:17:50.553199Z","shell.execute_reply.started":"2025-04-03T10:17:41.560532Z","shell.execute_reply":"2025-04-03T10:17:50.552233Z"},"trusted":true},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33med24s401\u001b[0m (\u001b[33med24s401-indian-institute-of-technology-madras\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"!pip install thop -q","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T12:11:48.861885Z","iopub.execute_input":"2025-04-03T12:11:48.862205Z","iopub.status.idle":"2025-04-03T12:11:54.901344Z","shell.execute_reply.started":"2025-04-03T12:11:48.862182Z","shell.execute_reply":"2025-04-03T12:11:54.899562Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"from torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T11:35:17.119033Z","iopub.execute_input":"2025-04-03T11:35:17.119377Z","iopub.status.idle":"2025-04-03T11:35:17.124468Z","shell.execute_reply.started":"2025-04-03T11:35:17.119352Z","shell.execute_reply":"2025-04-03T11:35:17.123082Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# transformations for training and testing\ntransform_train = transforms.Compose([\n    transforms.Resize((224,224)),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5),\n                         (0.5, 0.5, 0.5))\n\n])\ntransform_test = transforms.Compose([\n    transforms.Resize((224,224)),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5),\n                         (0.5, 0.5, 0.5))\n])\n\n\n\ntrain_dataset = datasets.ImageFolder(root='/kaggle/input/nature-12k/inaturalist_12K/train', transform=transform_train)\n\ntest_dataset = datasets.ImageFolder(root='/kaggle/input/nature-12k/inaturalist_12K/val', transform=transform_test)\n\n\n\n# Creating Dataloaders\n\ntrain_loader= DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\ntrain_loader= DataLoader(train_dataset, batch_size=64, shuffle=False, num_workers=2)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T11:36:19.253759Z","iopub.execute_input":"2025-04-03T11:36:19.254135Z","iopub.status.idle":"2025-04-03T11:36:21.161413Z","shell.execute_reply.started":"2025-04-03T11:36:19.254108Z","shell.execute_reply":"2025-04-03T11:36:21.160140Z"}},"outputs":[{"name":"stdout","text":"11999\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass FlexibleCNN(nn.Module):\n  def __init__(\n      self,\n      in_channels= 3,\n      conv_channels=[32, 64, 128, 256, 512],\n      kernel_size= 3,\n      activation =nn.ReLU,\n      num_classes=10,\n      init_image_size=224,\n      dense_neurons=512\n    ):\n    \n    super(FlexibleCNN, self).__init__()\n\n    self.activation=activation()\n\n    # Building Conv Layers\n\n    conv_layers =[]\n    current_in_channels =in_channels\n    current_image_size=init_image_size\n\n    for out_channels in conv_channels:\n\n      # Conv layer\n      conv_layers.append(nn.Conv2d(\n          in_channels=current_in_channels,\n          out_channels=out_channels,\n          kernel_size=kernel_size,\n          stride=1,\n          padding= kernel_size // 2\n      \n\n      ))\n\n      # Activation\n      conv_layers.append(activation())\n\n      # Max Pooling\n      conv_layers.append(nn.MaxPool2d(kernel_size=2, stride=2))\n\n      # Update for next iteration\n      current_in_channels = out_channels\n      current_image_size = current_image_size // 2\n\n    # Sequential Combination of all conc layers\n    self.conv_layers =nn.Sequential(*conv_layers)\n\n    # Flattening\n    flattened_dim = current_in_channels * current_image_size**2\n\n    self.fc1 = nn.Linear(flattened_dim, dense_neurons)\n    self.fc2 = nn.Linear(dense_neurons, num_classes)\n\n\n  def forward(self, x):\n\n    # Pass through all conv + pool blocks\n\n    x= self.conv_layers(x)\n\n    # FLatten\n    x = x.view(x.size(0), -1)\n\n    # Fully layers with activation\n    x=self.activation(self.fc1(x))\n    x=self.fc2(x)\n    \n    return x\n\n\nmodel = FlexibleCNN(\n    in_channels=3,\n    conv_channels=[32, 64, 128, 256, 512],\n    kernel_size=3,\n    activation=nn.ReLU,\n    num_classes=len(train_dataset.classes),  # For iNaturalist or any other dataset\n    init_image_size=224,  # If your images are resized to 224x224\n    dense_neurons=1024     # Example size for the penultimate layer\n)\n\n#print(type(model))\n# \ndevice =torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)\n\nprint(type(model))\n\ndef count_parameters(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n\ntotal_params = count_parameters(model)\nprint(\"Total trainable parameters:\", total_params)\n\nfrom thop import profile\n\n# Create a dummy input tensor with batch size 1 and appropriate dimensions\ndummy_input = torch.randn(1, 3, 224, 224).to(device)\nmacs, params = profile(model, inputs=(dummy_input,), verbose=False)\nprint(\"Total MACs:\", macs)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T12:12:00.547326Z","iopub.execute_input":"2025-04-03T12:12:00.547693Z","iopub.status.idle":"2025-04-03T12:12:01.055308Z","shell.execute_reply.started":"2025-04-03T12:12:00.547638Z","shell.execute_reply":"2025-04-03T12:12:01.054172Z"}},"outputs":[{"name":"stdout","text":"<class '__main__.FlexibleCNN'>\nTotal trainable parameters: 27269962\nTotal MACs: 993896448.0\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"#### QUESTION 2","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}